{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Exploration & Documentation Review (15 mins)\n",
    "Review YouTube API docs for videos endpoint <br>\n",
    "Understand pagination for historical data <br>\n",
    "Check API quotas and limits <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 06:08:48,244 - INFO - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching channel details...\n",
      "Data saved to data/raw/channel_details_20241222_060848.json\n",
      "\n",
      "Fetching videos from 2023...\n",
      "Data saved to data/raw/video_details_20241222_060851.json\n",
      "\n",
      "Fetched 131 videos\n",
      "API quota units used: 505\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def ensure_data_directories():\n",
    "    \"\"\"Create data directories if they don't exist\"\"\"\n",
    "    Path(\"data/raw\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def get_channel_details(youtube, channel_id):\n",
    "    \"\"\"Get detailed channel metrics\"\"\"\n",
    "    try:\n",
    "        request = youtube.channels().list(\n",
    "            part=\"snippet,statistics,brandingSettings\",\n",
    "            id=channel_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        if 'items' in response and response['items']:\n",
    "            channel = response['items'][0]\n",
    "            \n",
    "            return {\n",
    "                # Primary Key\n",
    "                'channel_id': channel_id,\n",
    "                \n",
    "                # Core Metadata\n",
    "                'channel_name': channel['snippet']['title'],\n",
    "                'channel_url': f\"https://www.youtube.com/channel/{channel_id}\",\n",
    "                'country': channel['snippet'].get('country', 'Unknown'),\n",
    "                'joined_date': channel['snippet']['publishedAt'],\n",
    "                \n",
    "                # Performance Metrics\n",
    "                'subscriber_count': int(channel['statistics']['subscriberCount']),\n",
    "                'total_views': int(channel['statistics']['viewCount']),\n",
    "                \n",
    "                # Audit Fields\n",
    "                'extracted_at': datetime.now().isoformat(),\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting channel details: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def parse_duration(duration):\n",
    "    \"\"\"Convert YouTube duration (PT1H2M10S) to seconds\"\"\"\n",
    "    match = re.match(r'PT((?P<hours>\\d+)H)?((?P<minutes>\\d+)M)?((?P<seconds>\\d+)S)?', duration)\n",
    "    if not match:\n",
    "        return 0\n",
    "    \n",
    "    parts = {k: int(v) for k, v in match.groupdict().items() if v}\n",
    "    return parts.get('hours', 0) * 3600 + parts.get('minutes', 0) * 60 + parts.get('seconds', 0)\n",
    "\n",
    "def get_video_details(youtube, channel_id, start_date=None, end_date=None, max_results=None):\n",
    "    \"\"\"\n",
    "    Get video metrics (excluding shorts) within a date range\n",
    "    \n",
    "    Quota usage per iteration:\n",
    "    - search().list() = 100 units\n",
    "    - videos().list() = 1 unit per video (max 50 per request)\n",
    "    \"\"\"\n",
    "    videos = []\n",
    "    next_page_token = None\n",
    "    quota_used = 0\n",
    "    \n",
    "    # Convert dates to datetime if provided\n",
    "    if start_date:\n",
    "        start_date = datetime.fromisoformat(start_date.replace('Z', '+00:00')).replace(tzinfo=None)\n",
    "    if end_date:\n",
    "        end_date = datetime.fromisoformat(end_date.replace('Z', '+00:00')).replace(tzinfo=None)\n",
    "\n",
    "    def clean_text(text):\n",
    "        \"\"\"Clean unicode characters and HTML entities from text\"\"\"\n",
    "        text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "        text = text.replace('&amp;', '&')\n",
    "        text = text.replace('&#39;', \"'\")\n",
    "        return text.strip()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Get videos sorted by date\n",
    "            request = youtube.search().list(\n",
    "                part=\"snippet\",\n",
    "                channelId=channel_id,\n",
    "                maxResults=50,\n",
    "                order=\"date\",\n",
    "                type=\"video\",\n",
    "                pageToken=next_page_token,\n",
    "                publishedAfter=start_date.isoformat() + 'Z',\n",
    "                publishedBefore=end_date.isoformat() + 'Z'\n",
    "            )\n",
    "            search_response = request.execute()\n",
    "            quota_used += 100\n",
    "            \n",
    "            if not search_response.get('items'):\n",
    "                break\n",
    "\n",
    "            video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "            \n",
    "            # Get detailed video info\n",
    "            video_request = youtube.videos().list(\n",
    "                part=\"contentDetails,statistics\",\n",
    "                id=','.join(video_ids)\n",
    "            )\n",
    "            video_response = video_request.execute()\n",
    "            quota_used += 1\n",
    "\n",
    "            # Process each video\n",
    "            for search_item, video_item in zip(search_response['items'], video_response['items']):\n",
    "                upload_datetime = datetime.fromisoformat(\n",
    "                    search_item['snippet']['publishedAt'].replace('Z', '+00:00')\n",
    "                ).replace(tzinfo=None)\n",
    "                \n",
    "                duration = video_item['contentDetails']['duration']\n",
    "                \n",
    "                # Skip shorts (videos under 60 seconds)\n",
    "                if parse_duration(duration) < 60:\n",
    "                    continue\n",
    "                \n",
    "                videos.append({\n",
    "                    'video_id': search_item['id']['videoId'],\n",
    "                    'channel_id': channel_id,\n",
    "                    'title': clean_text(search_item['snippet']['title']),\n",
    "                    'url': f\"https://www.youtube.com/watch?v={search_item['id']['videoId']}\",\n",
    "                    'duration_seconds': parse_duration(duration),\n",
    "                    'view_count': int(video_item['statistics']['viewCount']),\n",
    "                    'upload_datetime': upload_datetime.isoformat(),\n",
    "                    'extracted_at': datetime.now().isoformat()\n",
    "                })\n",
    "                \n",
    "                if max_results and len(videos) >= max_results:\n",
    "                    return videos, quota_used\n",
    "\n",
    "            next_page_token = search_response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "\n",
    "        return videos, quota_used\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting video details: {str(e)}\")\n",
    "        return None, quota_used\n",
    "\n",
    "def save_data(data, filename):\n",
    "    \"\"\"Save data to JSON file with timestamp\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filepath = Path(f\"data/raw/{filename}_{timestamp}.json\")\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Data saved to {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create data directories\n",
    "    ensure_data_directories()\n",
    "    \n",
    "    # Initialize API connection\n",
    "    load_dotenv()\n",
    "    youtube = build('youtube', 'v3', \n",
    "                   developerKey=os.getenv('YOUTUBE_API_KEY'))\n",
    "    \n",
    "    channel_id = \"UCbCmjCuTUZos6Inko4u57UQ\"  # Cocomelon\n",
    "    \n",
    "    # Get channel details\n",
    "    print(\"\\nFetching channel details...\")\n",
    "    channel_data = get_channel_details(youtube, channel_id)\n",
    "    if channel_data:\n",
    "        save_data(channel_data, \"channel_details\")\n",
    "    \n",
    "    # Get all videos from 2023\n",
    "    print(\"\\nFetching videos from 2023...\")\n",
    "    videos, quota_used = get_video_details(\n",
    "        youtube,\n",
    "        channel_id,\n",
    "        start_date=\"2023-01-01T00:00:00\",\n",
    "        end_date=\"2023-12-31T23:59:59\"\n",
    "    )\n",
    "    \n",
    "    if videos:\n",
    "        save_data(videos, \"video_details\")\n",
    "        print(f\"\\nFetched {len(videos)} videos\")\n",
    "        print(f\"API quota units used: {quota_used}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
